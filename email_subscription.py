#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
arXiv RSS Filter Bot - Email Subscription Module
arXiv RSS è¿‡æ»¤æœºå™¨äºº - é‚®ä»¶è®¢é˜…æ¨¡å—

è¯¥æ¨¡å—è´Ÿè´£å°†æœ€æ–°çš„RSSå†…å®¹å‘é€åˆ°è®¢é˜…é‚®ç®±ï¼Œé¿å…å‘é€é‡å¤çš„è®ºæ–‡ã€‚
"""

import os
import json
import logging
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timezone
import xml.etree.ElementTree as ET
from config_loader import load_config
import re
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å®šä¹‰ç›®å½•è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_DIR = os.path.join(SCRIPT_DIR, "history")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output")
SUBSCRIPTION_HISTORY_FILE = os.path.join(SCRIPT_DIR, "subscription_history.json")

def load_subscription_history():
    """
    åŠ è½½è®¢é˜…å†å²è®°å½•ï¼Œç”¨äºé¿å…å‘é€é‡å¤çš„è®ºæ–‡
    
    Returns:
        dict: åŒ…å«å·²å‘é€è®ºæ–‡IDçš„å­—å…¸
    """
    if not os.path.exists(SUBSCRIPTION_HISTORY_FILE):
        return {"sent_papers": [], "last_sent": None}
    
    try:
        with open(SUBSCRIPTION_HISTORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"åŠ è½½è®¢é˜…å†å²è®°å½•å¤±è´¥: {str(e)}")
        return {"sent_papers": [], "last_sent": None}

def save_subscription_history(history):
    """
    ä¿å­˜è®¢é˜…å†å²è®°å½•
    
    Args:
        history (dict): åŒ…å«å·²å‘é€è®ºæ–‡IDçš„å­—å…¸
    """
    try:
        with open(SUBSCRIPTION_HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2)
        logger.info(f"è®¢é˜…å†å²è®°å½•å·²ä¿å­˜åˆ° {SUBSCRIPTION_HISTORY_FILE}")
    except Exception as e:
        logger.error(f"ä¿å­˜è®¢é˜…å†å²è®°å½•å¤±è´¥: {str(e)}")

def get_latest_rss_file():
    """
    è·å–æœ€æ–°çš„RSSæ–‡ä»¶
    
    Returns:
        str: æœ€æ–°RSSæ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    if not os.path.exists(OUTPUT_DIR):
        logger.error(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {OUTPUT_DIR}")
        return None
        
    rss_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.xml')]
    if not rss_files:
        logger.info("æ²¡æœ‰æ‰¾åˆ°RSSæ–‡ä»¶")
        return None
        
    # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    rss_files.sort(key=lambda f: os.path.getmtime(os.path.join(OUTPUT_DIR, f)), reverse=True)
    return os.path.join(OUTPUT_DIR, rss_files[0])

def parse_rss_file(rss_file):
    """
    è§£æRSSæ–‡ä»¶ï¼Œæå–è®ºæ–‡ä¿¡æ¯
    
    Args:
        rss_file (str): RSSæ–‡ä»¶è·¯å¾„
        
    Returns:
        list: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
    """
    try:
        tree = ET.parse(rss_file)
        root = tree.getroot()
        
        papers = []
        for item in root.findall('./channel/item'):
            paper = {
                'title': item.find('title').text if item.find('title') is not None else 'No Title',
                'link': item.find('link').text if item.find('link') is not None else '',
                'description': item.find('description').text if item.find('description') is not None else '',
                'guid': item.find('guid').text if item.find('guid') is not None else '',
                'pubDate': item.find('pubDate').text if item.find('pubDate') is not None else ''
            }
            papers.append(paper)
            
        return papers
    except Exception as e:
        logger.error(f"è§£æRSSæ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

def classify_paper(paper, categories_config):
    """
    æ ¹æ®æ ‡é¢˜å’Œæ‘˜è¦å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»
    
    Args:
        paper (dict): è®ºæ–‡ä¿¡æ¯
        categories_config (dict): åˆ†ç±»é…ç½®
        
    Returns:
        str: åˆ†ç±»åç§°ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å›'ğŸ”§ Other AI/ML'
    """
    title = paper['title'].lower()
    description = paper['description'].lower()
    text_content = f"{title} {description}"
    
    # éå†æ‰€æœ‰åˆ†ç±»ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„
    for category_name, keywords in categories_config.items():
        for keyword in keywords:
            if keyword.lower() in text_content:
                return category_name
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•åˆ†ç±»ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
    return "ğŸ”§ Other AI/ML"

def parse_pub_date(pub_date_str):
    """
    è§£æå‘å¸ƒæ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
    
    Args:
        pub_date_str (str): å‘å¸ƒæ—¥æœŸå­—ç¬¦ä¸²
        
    Returns:
        datetime: è§£æåçš„æ—¥æœŸå¯¹è±¡
    """
    try:
        from email.utils import parsedate_to_datetime
        return parsedate_to_datetime(pub_date_str)
    except:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå¾ˆè€çš„æ—¥æœŸï¼Œç¡®ä¿æ’åºæ—¶æ’åœ¨åé¢
        return datetime(1900, 1, 1, tzinfo=timezone.utc)

def categorize_and_sort_papers(papers, config):
    """
    å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»å¹¶æŒ‰æ—¶é—´æ’åº
    
    Args:
        papers (list): è®ºæ–‡åˆ—è¡¨
        config (dict): é…ç½®ä¿¡æ¯
        
    Returns:
        dict: æŒ‰åˆ†ç±»ç»„ç»‡çš„è®ºæ–‡å­—å…¸ï¼Œæ¯ä¸ªåˆ†ç±»å†…æŒ‰æ—¶é—´é™åºæ’åº
    """
    categories_config = config.get('paper_categories', {})
    if not categories_config:
        # å¦‚æœæ²¡æœ‰é…ç½®åˆ†ç±»ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»
        categories_config = {"ğŸ”§ All Papers": []}
    
    # æŒ‰åˆ†ç±»ç»„ç»‡è®ºæ–‡
    categorized_papers = defaultdict(list)
    
    for paper in papers:
        # è§£æå‘å¸ƒæ—¥æœŸ
        paper['parsed_date'] = parse_pub_date(paper.get('pubDate', ''))
        
        # åˆ†ç±»è®ºæ–‡
        category = classify_paper(paper, categories_config)
        categorized_papers[category].append(paper)
    
    # æ¯ä¸ªåˆ†ç±»å†…æŒ‰æ—¶é—´é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    for category in categorized_papers:
        categorized_papers[category].sort(
            key=lambda x: x['parsed_date'], 
            reverse=True
        )
    
    # æŒ‰åˆ†ç±»åç§°æ’åºï¼Œç¡®ä¿ä¸€è‡´çš„æ˜¾ç¤ºé¡ºåº
    sorted_categories = dict(sorted(categorized_papers.items()))
    
    return sorted_categories

def send_subscription_email(papers, config):
    """
    å‘é€è®¢é˜…é‚®ä»¶
    
    Args:
        papers (list): è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
        config (dict): é…ç½®ä¿¡æ¯
        
    Returns:
        bool: æ˜¯å¦å‘é€æˆåŠŸ
    """
    if not papers:
        logger.info("æ²¡æœ‰æ–°è®ºæ–‡éœ€è¦å‘é€")
        return False
        
    # ä»é…ç½®ä¸­è·å–é‚®ä»¶å‚æ•°
    email_config = config.get('email', {})
    smtp_server = email_config.get('smtp_server')
    port = email_config.get('port', 587)
    username = email_config.get('username')
    password = email_config.get('password')
    recipient = email_config.get('recipient')
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®
    if not all([smtp_server, username, password, recipient]):
        logger.error("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•å‘é€è®¢é˜…é‚®ä»¶")
        return False
        
    try:
        # å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»å’Œæ’åº
        categorized_papers = categorize_and_sort_papers(papers, config)
        total_papers = sum(len(papers_in_cat) for papers_in_cat in categorized_papers.values())
        
        # åˆ›å»ºé‚®ä»¶
        msg = MIMEMultipart()
        msg['From'] = username
        msg['To'] = recipient
        msg['Subject'] = f"arXiv RSS Filter Bot - æœ€æ–°è®ºæ–‡æ›´æ–° ({datetime.now().strftime('%Y-%m-%d')})"
        
        # æ„å»ºé‚®ä»¶æ­£æ–‡
        body = f"""<html>
<head>
  <style>
    body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
    .category {{ margin-bottom: 30px; }}
    .category-title {{ 
      font-size: 20px; 
      font-weight: bold; 
      color: #2c3e50; 
      margin-bottom: 15px;
      padding-bottom: 5px;
      border-bottom: 2px solid #3498db;
    }}
    .paper {{ 
      margin-bottom: 20px; 
      padding: 15px; 
      border: 1px solid #e0e0e0; 
      border-radius: 8px;
      background-color: #f9f9f9;
    }}
    .title {{ font-size: 16px; font-weight: bold; color: #1a0dab; margin-bottom: 5px; }}
    .link {{ color: #1a0dab; text-decoration: none; }}
    .link:hover {{ text-decoration: underline; }}
    .pub-date {{ font-size: 12px; color: #666; margin-bottom: 8px; }}
    .description {{ font-size: 14px; color: #333; }}
    .category-summary {{ font-size: 14px; color: #7f8c8d; margin-bottom: 10px; }}
  </style>
</head>
<body>
  <h2>ğŸ¯ arXiv RSS Filter Bot - æœ€æ–°è®ºæ–‡æ›´æ–°</h2>
  <p>å…±æ‰¾åˆ° <strong>{total_papers}</strong> ç¯‡ç¬¦åˆæ‚¨å…´è¶£çš„æœ€æ–°è®ºæ–‡ï¼ŒæŒ‰ç±»åˆ«æ•´ç†å¦‚ä¸‹ï¼š</p>
"""
        
        # æŒ‰åˆ†ç±»æ·»åŠ è®ºæ–‡
        for category_name, papers_in_category in categorized_papers.items():
            if not papers_in_category:
                continue
                
            body += f"""
  <div class="category">
    <div class="category-title">{category_name}</div>
    <div class="category-summary">æœ¬ç±»åˆ«å…± {len(papers_in_category)} ç¯‡è®ºæ–‡ï¼ŒæŒ‰å‘è¡¨æ—¶é—´æ’åºï¼š</div>
"""
            
            for paper in papers_in_category:
                title = paper['title']
                link = paper['link']
                pub_date = paper['pubDate']
                
                # å¤„ç†æ‘˜è¦å†…å®¹å’Œä½œè€…ä¿¡æ¯
                description = paper['description'] if paper['description'] else 'æ— æ‘˜è¦'
                authors = 'æš‚æ— ä½œè€…ä¿¡æ¯'
                
                if description != 'æ— æ‘˜è¦':
                    lines = description.split('\n')
                    abstract_lines = []
                    found_authors = False
                    
                    for line in lines:
                        if line.strip().startswith('Authors:'):
                            # æå–ä½œè€…ä¿¡æ¯
                            authors = line.strip().replace('Authors:', '').strip()
                            found_authors = True
                            continue
                        if found_authors and line.strip():
                            abstract_lines.append(line.strip())
                    
                    # å°†æ‘˜è¦åˆå¹¶ä¸ºè¿è´¯çš„æ®µè½
                    if abstract_lines:
                        description = ' '.join(abstract_lines)
                    else:
                        # å¦‚æœæ²¡æ‰¾åˆ°Authors:è¡Œï¼Œä½¿ç”¨åŸå§‹æè¿°ä½†å»é™¤å¤šä½™æ¢è¡Œ
                        description = ' '.join(line.strip() for line in lines if line.strip())
                
                body += f"""
    <div class="paper">
      <div class="title"><a href="{link}" class="link">{title}</a></div>
      <div class="pub-date">ğŸ“… å‘è¡¨æ—¥æœŸ: {pub_date}</div>
      <div class="pub-date">ğŸ‘¥ ä½œè€…: {authors}</div>
      <div class="description">{description}</div>
    </div>
"""
            
            body += "  </div>"  # å…³é—­category div
        
        body += """
  <hr style="margin-top: 40px; border: none; border-top: 1px solid #bdc3c7;">
  <p style="text-align: center; color: #7f8c8d; font-size: 12px;">
    ç”± arXiv RSS Filter Bot è‡ªåŠ¨ç”Ÿæˆ | æ¯æ—¥è‡ªåŠ¨æ¨é€æœ€æ–°è®ºæ–‡
  </p>
</body></html>"""
        
        # æ·»åŠ HTMLæ­£æ–‡
        msg.attach(MIMEText(body, 'html'))
        
        # å‘é€é‚®ä»¶
        with smtplib.SMTP(smtp_server, port) as server:
            server.starttls()
            server.login(username, password)
            server.send_message(msg)
            
        logger.info(f"æˆåŠŸå‘é€è®¢é˜…é‚®ä»¶åˆ° {recipient}")
        return True
            
    except Exception as e:
        logger.error(f"å‘é€è®¢é˜…é‚®ä»¶å¤±è´¥: {str(e)}")
        return False

def run_subscription():
    """
    è¿è¡Œè®¢é˜…åŠŸèƒ½
    """
    logger.info("å¼€å§‹è¿è¡Œè®¢é˜…åŠŸèƒ½")
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨é‚®ä»¶è®¢é˜…
    if not config.get('email_subscription', False):
        logger.info("é‚®ä»¶è®¢é˜…åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡")
        return False
    
    # æ£€æŸ¥é‚®ä»¶é…ç½®æ˜¯å¦å®Œæ•´
    email_config = config.get('email', {})
    required_fields = ['smtp_server', 'port', 'username', 'password', 'recipient']
    missing_fields = [field for field in required_fields if not email_config.get(field)]
    
    if missing_fields:
        logger.error(f"é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
        return False
    
    # åŠ è½½è®¢é˜…å†å²è®°å½•
    subscription_history = load_subscription_history()
    sent_papers = set(subscription_history.get("sent_papers", []))
    logger.info(f"å·²åŠ è½½è®¢é˜…å†å²è®°å½•ï¼Œå…±æœ‰ {len(sent_papers)} ç¯‡å·²å‘é€è®ºæ–‡")
    
    # è·å–æœ€æ–°çš„RSSæ–‡ä»¶
    latest_rss = get_latest_rss_file()
    if not latest_rss:
        logger.info("æ²¡æœ‰æ‰¾åˆ°RSSæ–‡ä»¶ï¼Œæ— æ³•å‘é€è®¢é˜…é‚®ä»¶")
        return False
        
    # è§£æRSSæ–‡ä»¶
    all_papers = parse_rss_file(latest_rss)
    logger.info(f"ä»RSSæ–‡ä»¶ä¸­è§£æåˆ° {len(all_papers)} ç¯‡è®ºæ–‡")
    
    # è¿‡æ»¤å‡ºæ–°è®ºæ–‡
    new_papers = [p for p in all_papers if p['guid'] not in sent_papers]
    logger.info(f"æ‰¾åˆ° {len(new_papers)} ç¯‡æ–°è®ºæ–‡")
    
    if new_papers:
        # å‘é€è®¢é˜…é‚®ä»¶
        success = send_subscription_email(new_papers, config)
        
        if success:
            # æ›´æ–°è®¢é˜…å†å²è®°å½•
            for paper in new_papers:
                sent_papers.add(paper['guid'])
            
            subscription_history["sent_papers"] = list(sent_papers)
            subscription_history["last_sent"] = datetime.now().isoformat()
            save_subscription_history(subscription_history)
            
            logger.info(f"æˆåŠŸå‘é€ {len(new_papers)} ç¯‡æ–°è®ºæ–‡ï¼Œå¹¶æ›´æ–°äº†è®¢é˜…å†å²è®°å½•")
            return True
        else:
            logger.error("å‘é€è®¢é˜…é‚®ä»¶å¤±è´¥")
    else:
        logger.info("æ²¡æœ‰æ–°è®ºæ–‡éœ€è¦å‘é€")
        
    return False

if __name__ == "__main__":
    run_subscription() 