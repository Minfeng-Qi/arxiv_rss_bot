#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Notioné›†æˆæ¨¡å—
ç”¨äºå°†AIåˆ†æç»“æœä¿å­˜åˆ°Notionæ•°æ®åº“
"""

import json
import logging
import requests
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from config_loader import load_config

logger = logging.getLogger(__name__)

class NotionIntegrator:
    """Notioné›†æˆå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–Notioné›†æˆå™¨"""
        self.config = config
        ai_config = config.get('ai_analysis', {})
        notion_config = ai_config.get('notion', {})
        
        self.integration_token = notion_config.get('integration_token', '')
        self.database_id = notion_config.get('database_id', '')
        self.enabled = notion_config.get('enabled', False)
        
        self.base_url = 'https://api.notion.com/v1'
        self.headers = {
            'Authorization': f'Bearer {self.integration_token}',
            'Content-Type': 'application/json',
            'Notion-Version': '2022-06-28'
        }
        
        if not self.integration_token or not self.enabled:
            logger.warning("Notioné›†æˆæœªå¯ç”¨æˆ–ä»¤ç‰Œæœªé…ç½®")
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨Notioné›†æˆ"""
        return self.enabled and bool(self.integration_token) and bool(self.database_id)
    
    def test_connection(self) -> bool:
        """æµ‹è¯•Notionè¿æ¥"""
        if not self.integration_token:
            logger.error("Notioné›†æˆä»¤ç‰Œæœªé…ç½®")
            return False
        
        try:
            # æµ‹è¯•APIè¿æ¥
            response = requests.get(
                f"{self.base_url}/users/me",
                headers=self.headers,
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info("Notionè¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logger.error(f"Notionè¿æ¥æµ‹è¯•å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Notionè¿æ¥æµ‹è¯•å¼‚å¸¸: {str(e)}")
            return False
    
    def create_database_page(self, analysis_result: Dict[str, Any]) -> bool:
        """åœ¨Notionæ•°æ®åº“ä¸­åˆ›å»ºé¡µé¢"""
        if not self.is_enabled():
            logger.warning("Notioné›†æˆæœªå¯ç”¨")
            return False
        
        if not self.database_id:
            logger.error("Notionæ•°æ®åº“IDæœªé…ç½®")
            return False
        
        try:
            # æ„å»ºé¡µé¢å±æ€§
            properties = self._build_page_properties(analysis_result)
            
            # æ„å»ºé¡µé¢å†…å®¹
            children = self._build_page_content(analysis_result)
            
            page_data = {
                'parent': {'database_id': self.database_id},
                'properties': properties,
                'children': children
            }
            
            response = requests.post(
                f"{self.base_url}/pages",
                headers=self.headers,
                json=page_data,
                timeout=30
            )
            
            if response.status_code == 200:
                page_info = response.json()
                page_url = page_info.get('url', '')
                logger.info(f"æˆåŠŸåˆ›å»ºNotioné¡µé¢: {page_url}")
                return True
            else:
                logger.error(f"åˆ›å»ºNotioné¡µé¢å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"åˆ›å»ºNotioné¡µé¢å¼‚å¸¸: {str(e)}")
            return False
    
    def _build_page_properties(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºé¡µé¢å±æ€§ï¼ˆé€‚é…ç°æœ‰æ•°æ®åº“ç»“æ„ï¼‰"""
        analysis = analysis_result.get('analysis', {})
        
        properties = {
            'æ ‡é¢˜': {
                'title': [
                    {
                        'text': {
                            'content': analysis_result.get('title', 'æœªçŸ¥æ ‡é¢˜')
                        }
                    }
                ]
            },
            'è®ºæ–‡ID': {
                'rich_text': [
                    {
                        'text': {
                            'content': analysis_result.get('paper_id', '')
                        }
                    }
                ]
            },
            'åˆ†ææ—¥æœŸ': {
                'date': {
                    'start': analysis_result.get('analysis_date', datetime.now().isoformat())[:10]
                }
            },
            'å‘å¸ƒæ—¥æœŸ': {
                'date': {
                    'start': self._parse_date(analysis_result.get('published_date', ''))
                }
            },
            'çŠ¶æ€': {
                'select': {
                    'name': analysis_result.get('status', 'success')
                }
            }
        }
        
        # æ·»åŠ è®ºæ–‡é“¾æ¥ï¼ˆå¦‚æœæœ‰arxiv_idï¼‰
        paper_id = analysis_result.get('paper_id', '')
        if paper_id:
            arxiv_url = f"https://arxiv.org/abs/{paper_id}"
            properties['è®ºæ–‡é“¾æ¥'] = {
                'url': arxiv_url
            }
        
        # é€‚é…ç°æœ‰å­—æ®µ
        # ä½¿ç”¨"åˆ†ç±»"å­—æ®µä»£æ›¿"ç±»åˆ«"
        category = analysis.get('category', 'Other')
        properties['åˆ†ç±»'] = {
            'select': {
                'name': category
            }
        }
        
        # ä½¿ç”¨"é‡è¦æ€§"å­—æ®µæ˜¾ç¤ºåˆ†æ•°ç­‰çº§
        score = analysis.get('score', 0.5)
        if score >= 0.8:
            importance = 'é«˜'
        elif score >= 0.6:
            importance = 'ä¸­'
        else:
            importance = 'ä½'
        
        properties['é‡è¦æ€§'] = {
            'select': {
                'name': importance
            }
        }
        
        # æ·»åŠ ä½œè€…ä¿¡æ¯
        authors = analysis_result.get('authors', [])
        if authors:
            authors_text = ', '.join(authors) if isinstance(authors, list) else str(authors)
            properties['ä½œè€…'] = {
                'rich_text': [
                    {
                        'text': {
                            'content': authors_text
                        }
                    }
                ]
            }
        
        # è®¾ç½®é¢†åŸŸæ ‡ç­¾
        keywords = analysis.get('keywords', [])
        if keywords:
            # å°†å…³é”®è¯ä½œä¸ºé¢†åŸŸæ ‡ç­¾
            field_options = []
            for keyword in keywords[:5]:  # æœ€å¤š5ä¸ªæ ‡ç­¾
                field_options.append({'name': keyword})
            
            properties['é¢†åŸŸ'] = {
                'multi_select': field_options
            }
        
        # åˆ¤æ–­æ˜¯å¦LLMç›¸å…³
        llm_keywords = ['large language model', 'LLM', 'GPT', 'language model', 'transformer']
        is_llm_related = any(keyword.lower() in str(analysis).lower() for keyword in llm_keywords)
        properties['æ˜¯å¦LLMç›¸å…³'] = {
            'checkbox': is_llm_related
        }
        
        return properties
    
    def _build_page_content(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ„å»ºé¡µé¢å†…å®¹"""
        analysis = analysis_result.get('analysis', {})
        
        children = []
        
        # æ·»åŠ æ ¸å¿ƒæ‘˜è¦
        core_summary = analysis.get('core_summary', '')
        if core_summary:
            children.extend([
                {
                    'object': 'block',
                    'type': 'heading_2',
                    'heading_2': {
                        'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ¯ æ ¸å¿ƒå†…å®¹'}}]
                    }
                },
                {
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': core_summary}}]
                    }
                }
            ])
        
        # æ·»åŠ å…³é”®æŠ€æœ¯
        key_techniques = analysis.get('key_techniques', [])
        if key_techniques:
            children.append({
                'object': 'block',
                'type': 'heading_2',
                'heading_2': {
                    'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ”§ å…³é”®æŠ€æœ¯'}}]
                }
            })
            
            for technique in key_techniques:
                children.append({
                    'object': 'block',
                    'type': 'bulleted_list_item',
                    'bulleted_list_item': {
                        'rich_text': [{'type': 'text', 'text': {'content': technique}}]
                    }
                })
        
        # æ·»åŠ ä¸»è¦è´¡çŒ®
        contributions = analysis.get('contributions', [])
        if contributions:
            children.append({
                'object': 'block',
                'type': 'heading_2',
                'heading_2': {
                    'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ’¡ ä¸»è¦è´¡çŒ®'}}]
                }
            })
            
            for contribution in contributions:
                children.append({
                    'object': 'block',
                    'type': 'bulleted_list_item',
                    'bulleted_list_item': {
                        'rich_text': [{'type': 'text', 'text': {'content': contribution}}]
                    }
                })
        
        # æ·»åŠ æ·±åº¦è§è§£
        insights = analysis.get('insights', '')
        if insights:
            children.extend([
                {
                    'object': 'block',
                    'type': 'heading_2',
                    'heading_2': {
                        'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ” æ·±åº¦è§è§£'}}]
                    }
                },
                {
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': insights}}]
                    }
                }
            ])
        
        # æ·»åŠ è¯„ä¼°
        evaluation = analysis.get('evaluation', '')
        if evaluation:
            children.extend([
                {
                    'object': 'block',
                    'type': 'heading_2',
                    'heading_2': {
                        'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ“Š æ–¹æ³•è¯„ä¼°'}}]
                    }
                },
                {
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': evaluation}}]
                    }
                }
            ])
        
        # æ·»åŠ å…³é”®è¯
        keywords = analysis.get('keywords', [])
        if keywords:
            keywords_text = ', '.join(keywords)
            children.extend([
                {
                    'object': 'block',
                    'type': 'heading_2',
                    'heading_2': {
                        'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ·ï¸ å…³é”®è¯'}}]
                    }
                },
                {
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': keywords_text}}]
                    }
                }
            ])
        
        # æ·»åŠ ä½œè€…ä¿¡æ¯
        authors = analysis_result.get('authors', [])
        if authors:
            authors_text = ', '.join(authors) if isinstance(authors, list) else str(authors)
            children.extend([
                {
                    'object': 'block',
                    'type': 'heading_2',
                    'heading_2': {
                        'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ‘¥ ä½œè€…'}}]
                    }
                },
                {
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': authors_text}}]
                    }
                }
            ])
        
        return children
    
    def _parse_date(self, date_str: str) -> str:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²"""
        if not date_str:
            return datetime.now().isoformat()[:10]
        
        try:
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            for fmt in ['%Y-%m-%d', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%SZ']:
                try:
                    dt = datetime.strptime(date_str[:len(fmt)], fmt)
                    return dt.strftime('%Y-%m-%d')
                except ValueError:
                    continue
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›å½“å‰æ—¥æœŸ
            return datetime.now().strftime('%Y-%m-%d')
            
        except Exception:
            return datetime.now().strftime('%Y-%m-%d')
    
    def sync_analysis_results(self, analysis_results: List[Dict[str, Any]]) -> int:
        """åŒæ­¥åˆ†æç»“æœåˆ°Notion"""
        if not self.is_enabled():
            logger.warning("Notioné›†æˆæœªå¯ç”¨ï¼Œè·³è¿‡åŒæ­¥")
            return 0
        
        if not analysis_results:
            logger.info("æ²¡æœ‰åˆ†æç»“æœéœ€è¦åŒæ­¥")
            return 0
        
        success_count = 0
        
        for i, result in enumerate(analysis_results, 1):
            try:
                logger.info(f"æ­£åœ¨åˆ›å»ºç¬¬ {i}/{len(analysis_results)} ä¸ªNotioné¡µé¢")
                
                if self.create_database_page(result):
                    success_count += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                if i < len(analysis_results):
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"åŒæ­¥ç¬¬ {i} ä¸ªç»“æœæ—¶å‡ºé”™: {str(e)}")
                continue
        
        logger.info(f"NotionåŒæ­¥å®Œæˆï¼ŒæˆåŠŸåˆ›å»º {success_count}/{len(analysis_results)} ä¸ªé¡µé¢")
        return success_count

def sync_to_notion(analysis_results: List[Dict[str, Any]], config: Dict[str, Any] = None) -> int:
    """ä¾¿æ·å‡½æ•°ï¼šåŒæ­¥åˆ†æç»“æœåˆ°Notion"""
    if config is None:
        config = load_config()
    
    integrator = NotionIntegrator(config)
    return integrator.sync_analysis_results(analysis_results)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    config = load_config()
    integrator = NotionIntegrator(config)
    
    if integrator.is_enabled():
        # æµ‹è¯•è¿æ¥
        if integrator.test_connection():
            print("Notionè¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            print("Notionè¿æ¥æµ‹è¯•å¤±è´¥")
    else:
        print("Notioné›†æˆæœªå¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")